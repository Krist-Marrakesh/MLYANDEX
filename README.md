Приступая к задаче, мы решили сначала разобраться в природе фото. Мы изучили, как работают GAN (в частности StyleGAN). Их слабое место — операции upsampling'а (увеличения разрешения), которые оставляют на изображении специфические следы: высокочастотный шум и "шахматные паттерны" (checkerboard artifacts).

Гипотеза: Стандартные архитектуры (вроде ResNet) агрессивно сжимают изображение (Pooling) на первых слоях, уничтожая эти мелкие, но важные детали.

решение:
Feature Engineering через Аугментации: Мы намеренно отказались от размытия (Blur) и использовали RandomAdjustSharpness. Это работает как "проявитель", делая шум генерации более контрастным для нейросети.
В начальных слоях (Stem) мы заменили классический MaxPool на свертки с шагом (Stride). Это позволило сохранить пиксельную сетку и текстурные аномалии, которые обычно теряются при пулинге.

Эволюция моделей: Мы прошли путь от ResNet до HRNet (High-Resolution Network). HRNet оказалась идеальным выбором, так как она поддерживает ветку высокого разрешения через всю глубину сети, позволяя модели одновременно видеть и "общую геометрию лица", и "микро-артефакты кожи".
# Deepfake Detection:
**Задача:** Бинарная классификация изображений (Real vs Deepfake).
**Целевая метрика:** F1-Score (с приоритетом на Recall).

## Ключевая идея (Our Approach)
Мы отталкивались от того, как именно GAN генерируют изображения. StyleGAN оставляет специфические артефакты (шум, checkerboard patterns) из-за несовершенства слоев upsampling'а.
Чтобы поймать эти артефакты, мы внедрили:
1.  **Artifact-Sensitive Augmentations:** Использование `RandomAdjustSharpness` для усиления высокочастотного шума.
2.  **No-Pooling Stem:** Отказ от `MaxPool` в первых слоях в пользу `Strided Convolutions` для сохранения текстурных деталей.
3.  **High-Resolution Architecture:** Использование кастомной **HRNet**, которая сохраняет пространственное разрешение признаков на протяжении всего прохода сети.

##  Исследования и Эксперименты

Мы протестировали несколько подходов, чтобы найти лучший баланс между Precision и Recall:

| Model Architecture | Augmentations | Loss Function | Best Val F1 | Notes |
|-------------------|---------------|---------------|-------------|-------|
| **Custom ResNet** | Basic | BCEWithLogits | ~0.65 | Базовое решение. Теряет детали из-за пулинга. |
| **Dual-Stream (RGB + FFT)** | Sharpness | Focal Loss | ~0.60 | Попытка использовать частотный анализ (Фурье). Оказалась шумной. |
| **Custom HRNet (Winner)** | **Sharpness** | **BCE** | **~0.80** | Параллельные ветки (High/Low Res) + Fusion. Лучший результат. |

## Техническая реализация
### 1. Борьба с дисбалансом (Imbalance Handling)
В датасете соотношение Real:Fake составляет ~5:1.
*   Использован **`WeightedRandomSampler`**: Гарантирует, что в каждом батче будет 50% реальных и 50% фейковых лиц.
*   Это позволило модели видеть достаточно примеров редкого класса (Fake) без использования жестких весов в функции потерь.

### 2. Динамический порог (Dynamic Thresholding)
Вместо фиксированного порога 0.5, мы реализовали алгоритм `find_best_threshold`, который на каждой эпохе ищет оптимальный порог классификации на валидационной выборке, максимизирующий F1-score.
*   Итоговый порог: **0.840** (обеспечивает высокий Precision при хорошем Recall).

